Linear algebra: Vectors; arithmetic with vectors; inner or dot product of
vectors, orthogonality; linear independence; basis vectors. Linear subspaces. Ma-
trices, matrix arithmetic, multiplying vectors and matrices; geometric meaning
of matrix multiplication. Eigenvalues and eigenvectors of matrices. Projection.
Calculus: Derivative, integral; fundamental theorem of calculus. Multivari-
able extensions: gradient, Hessian matrix, multidimensional integrals. Finding
minima and maxima with derivatives. Taylor approximations (App. B).
Probability: Random variable; distribution, population, sample. Cumula-
tive distribution function, probability mass function, probability density func-
tion. Specific distributions: Bernoulli, binomial, Poisson, geometric, Gaussian,
exponential, t, Gamma. Expectation value. Variance, standard deviation.
Joint distribution functions. Conditional distributions; conditional expecta-
tions and variances. Statistical independence and dependence. Covariance and
correlation; why dependence is not the same thing as correlation. Rules for arith-
metic with expectations, variances and covariances. Laws of total probability,
total expectation, total variation. Sequences of random variables. Stochastic pro-
cess. Law of large numbers. Central limit theorem.
Statistics: Sample mean, sample variance. Median, mode. Quartile, per-
centile, quantile. Inter-quartile range. Histograms. Contingency tables; odds ratio,
log odds ratio.
Parameters; estimator functions and point estimates. Sampling distribution.
Bias of an estimator. Standard error of an estimate; standard error of the mean;
how and why the standard error of the mean diﬀers from the standard deviation.
Consistency of estimators. Confidence intervals and interval estimates.
Hypothesis tests. Tests for diﬀerences in means and in proportions; Z and t
tests; degrees of freedom. Size, significance, power. Relation between hypothesis
tests and confidence intervals. χ2 test of independence for contingency tables;
degrees of freedom. KS test for goodness-of-fit to distributions.
Likelihood. Likelihood functions. Maximum likelihood estimates. Relation be-
tween confidence intervals and the likelihood function. Likelihood ratio test.
Regression: What a linear model is; distinction between the regressors and
the regressand. Predictions/fitted values and residuals of a regression. Interpre-
tation of regression coeﬃcients. Least-squares estimate of coeﬃcients. Relation
between maximum likelihood, least squares, and Gaussian distributions. Matrix
formula for estimating the coeﬃcients; the hat matrix for finding fitted values.
R2; why adding more predictor variables never reduces R2. The t-test for the sig-
nificance of individual coeﬃcients given other coeﬃcients. The F-test and partial
F-test for the significance of groups of coeﬃcients. Degrees of freedom for resid-
uals. Diagnostic examination of residuals. Confidence intervals for parameters.
Confidence intervals for fitted values. Prediction intervals.